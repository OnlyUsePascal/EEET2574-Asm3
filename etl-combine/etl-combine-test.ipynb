{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "# from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from numpy import float64, int64\n",
    "import numpy\n",
    "from dateutil import parser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URL=\"mongodb+srv://viphilongnguyen:egVQ0C3HhJRuVYaZ@cluster0.khgwh.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = pymongo.MongoClient(MONGO_URL)\n",
    "db = client.get_database('ASM3')\n",
    "\n",
    "# ====== REQUEST AREA ======\n",
    "def fetch_db(collection_name = ''):\n",
    "  collection = db[collection_name]\n",
    "  data = collection.find()\n",
    "  return pd.DataFrame(list(data))\n",
    "  # return list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   _id           2000 non-null   object \n",
      " 1   city          2000 non-null   object \n",
      " 2   cloudiness    2000 non-null   int64  \n",
      " 3   date          2000 non-null   object \n",
      " 4   feels_like    2000 non-null   float64\n",
      " 5   humidity      2000 non-null   int64  \n",
      " 6   latitude      2000 non-null   float64\n",
      " 7   longitude     2000 non-null   float64\n",
      " 8   pressure      2000 non-null   int64  \n",
      " 9   temperature   2000 non-null   float64\n",
      " 10  time          2000 non-null   object \n",
      " 11  visibility    2000 non-null   int64  \n",
      " 12  weather_desc  2000 non-null   object \n",
      " 13  weather_main  2000 non-null   object \n",
      " 14  wind_deg      2000 non-null   int64  \n",
      " 15  wind_speed    2000 non-null   float64\n",
      "dtypes: float64(5), int64(5), object(6)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_clean = fetch_db('weather_clean')\n",
    "weather_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   _id             327 non-null    object \n",
      " 1   city            327 non-null    object \n",
      " 2   co              327 non-null    float64\n",
      " 3   date            327 non-null    object \n",
      " 4   gb-defra-index  327 non-null    int64  \n",
      " 5   o3              327 non-null    float64\n",
      " 6   pm10            327 non-null    float64\n",
      " 7   pm2_5           327 non-null    float64\n",
      " 8   so2             327 non-null    float64\n",
      " 9   time            327 non-null    object \n",
      " 10  us-epa-index    327 non-null    int64  \n",
      " 11  uv              327 non-null    float64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 30.8+ KB\n"
     ]
    }
   ],
   "source": [
    "air_clean = fetch_db('air_clean')\n",
    "air_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5080 entries, 0 to 5079\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   _id               5080 non-null   object \n",
      " 1   city              5080 non-null   object \n",
      " 2   date              5080 non-null   object \n",
      " 3   delay             5080 non-null   float64\n",
      " 4   event_code        5080 non-null   int64  \n",
      " 5   event_desc        5080 non-null   object \n",
      " 6   iconCategory      5080 non-null   int64  \n",
      " 7   length            5080 non-null   float64\n",
      " 8   magnitudeOfDelay  5080 non-null   int64  \n",
      " 9   time              5080 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 397.0+ KB\n"
     ]
    }
   ],
   "source": [
    "traffic_clean = fetch_db('traffic_clean')\n",
    "traffic_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-01-07' '2024-11-12' '2024-12-07' '2025-01-04' '2025-01-06'\n",
      " '2024-10-29' '2024-11-23']\n",
      "['2025-01-06' '2025-01-07']\n",
      "['2025-01-07']\n"
     ]
    }
   ],
   "source": [
    "# traffic_clean[\"date\"].nunique().value()\n",
    "# print unique values of dates\n",
    "print(traffic_clean[\"date\"].unique())\n",
    "print(weather_clean[\"date\"].unique())\n",
    "print(air_clean[\"date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ho chi minh city' 'ha noi' 'da nang']\n",
      "['ho chi minh city' 'da nang' 'ha noi']\n",
      "['ho chi minh city' 'da nang' 'ha noi']\n"
     ]
    }
   ],
   "source": [
    "# i want to trim the whitespaces in the city column\n",
    "# print(traffic_clean[\"city\"].unique())\n",
    "# print(weather_clean[\"city\"].unique())\n",
    "# print(air_clean[\"city\"].unique())\n",
    "\n",
    "weather_clean[\"city\"] = weather_clean[\"city\"].replace(\"Ap Ba\", \"Da Nang\")\n",
    "weather_clean[\"city\"] = weather_clean[\"city\"].replace(\"Hanoi\", \"Ha Noi\")\n",
    "traffic_clean[\"city\"] = traffic_clean[\"city\"].replace(\"Hanoi\", \"Ha Noi\")\n",
    "\n",
    "traffic_clean[\"city\"] = traffic_clean[\"city\"].str.lower()\n",
    "weather_clean[\"city\"] = weather_clean[\"city\"].str.lower()\n",
    "air_clean[\"city\"] = air_clean[\"city\"].str.lower()\n",
    "print(traffic_clean[\"city\"].unique())\n",
    "print(weather_clean[\"city\"].unique())\n",
    "print(air_clean[\"city\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  7  6  9 17  1 15 16  2 14  5  3 10  4 13  0 23 21 12 11]\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16  1  2]\n",
      "[8 9]\n"
     ]
    }
   ],
   "source": [
    "# print(traffic_clean[\"time\"].unique())\n",
    "# print(weather_clean[\"time\"].unique())\n",
    "# print(air_clean[\"time\"].unique()) \n",
    "\n",
    "traffic_clean_1 = traffic_clean.copy()\n",
    "weather_clean_1 = weather_clean.copy()\n",
    "air_clean_1 = air_clean.copy()\n",
    "\n",
    "# Split the time column into hour and minute columns and convert them to numeric\n",
    "traffic_clean_1[\"hour\"] = traffic_clean_1[\"time\"].str.split(\":\", expand=True)[0].astype(int)\n",
    "traffic_clean_1[\"minute\"] = traffic_clean_1[\"time\"].str.split(\":\", expand=True)[1].astype(int)\n",
    "\n",
    "weather_clean_1[\"hour\"] = weather_clean_1[\"time\"].str.split(\":\", expand=True)[0].astype(int)\n",
    "weather_clean_1[\"minute\"] = weather_clean_1[\"time\"].str.split(\":\", expand=True)[1].astype(int)\n",
    "\n",
    "air_clean_1[\"hour\"] = air_clean_1[\"time\"].str.split(\":\", expand=True)[0].astype(int)\n",
    "air_clean_1[\"minute\"] = air_clean_1[\"time\"].str.split(\":\", expand=True)[1].astype(int)\n",
    "\n",
    "# Drop the original time column\n",
    "traffic_clean_1.drop(columns=[\"time\"], inplace=True)\n",
    "weather_clean_1.drop(columns=[\"time\"], inplace=True)\n",
    "air_clean_1.drop(columns=[\"time\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(traffic_clean_1[\"hour\"].unique())\n",
    "print(weather_clean_1[\"hour\"].unique())\n",
    "print(air_clean_1[\"hour\"].unique())\n",
    "\n",
    "#I want to see how many unnique values in all 3 dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2223 entries, 0 to 2222\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   _id_x             2223 non-null   object \n",
      " 1   city              2223 non-null   object \n",
      " 2   cloudiness        2223 non-null   int64  \n",
      " 3   date              2223 non-null   object \n",
      " 4   feels_like        2223 non-null   float64\n",
      " 5   humidity          2223 non-null   int64  \n",
      " 6   latitude          2223 non-null   float64\n",
      " 7   longitude         2223 non-null   float64\n",
      " 8   pressure          2223 non-null   int64  \n",
      " 9   temperature       2223 non-null   float64\n",
      " 10  visibility        2223 non-null   int64  \n",
      " 11  weather_desc      2223 non-null   object \n",
      " 12  weather_main      2223 non-null   object \n",
      " 13  wind_deg          2223 non-null   int64  \n",
      " 14  wind_speed        2223 non-null   float64\n",
      " 15  hour              2223 non-null   object \n",
      " 16  minute            2223 non-null   object \n",
      " 17  _id_y             2223 non-null   object \n",
      " 18  co                2223 non-null   float64\n",
      " 19  gb-defra-index    2223 non-null   int64  \n",
      " 20  o3                2223 non-null   float64\n",
      " 21  pm10              2223 non-null   float64\n",
      " 22  pm2_5             2223 non-null   float64\n",
      " 23  so2               2223 non-null   float64\n",
      " 24  us-epa-index      2223 non-null   int64  \n",
      " 25  uv                2223 non-null   float64\n",
      " 26  _id               2223 non-null   object \n",
      " 27  delay             2223 non-null   float64\n",
      " 28  event_code        2223 non-null   int64  \n",
      " 29  event_desc        2223 non-null   object \n",
      " 30  iconCategory      2223 non-null   int64  \n",
      " 31  length            2223 non-null   float64\n",
      " 32  magnitudeOfDelay  2223 non-null   int64  \n",
      "dtypes: float64(13), int64(10), object(10)\n",
      "memory usage: 573.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_data_1 = weather_clean_1.merge(air_clean_1, on=[\"date\", \"city\", \"hour\", \"minute\"], how=\"inner\") \\\n",
    "                                .merge(traffic_clean_1, on=[\"date\", \"city\", \"hour\", \"minute\"], how=\"inner\")\n",
    "\n",
    "print(merged_data_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id_x               0\n",
       "city                0\n",
       "cloudiness          0\n",
       "date                0\n",
       "feels_like          0\n",
       "humidity            0\n",
       "latitude            0\n",
       "longitude           0\n",
       "pressure            0\n",
       "temperature         0\n",
       "visibility          0\n",
       "weather_desc        0\n",
       "weather_main        0\n",
       "wind_deg            0\n",
       "wind_speed          0\n",
       "hour                0\n",
       "minute              0\n",
       "_id_y               0\n",
       "co                  0\n",
       "gb-defra-index      0\n",
       "o3                  0\n",
       "pm10                0\n",
       "pm2_5               0\n",
       "so2                 0\n",
       "us-epa-index        0\n",
       "uv                  0\n",
       "_id                 0\n",
       "delay               0\n",
       "event_code          0\n",
       "event_desc          0\n",
       "iconCategory        0\n",
       "length              0\n",
       "magnitudeOfDelay    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = merged_data_1.copy()\n",
    "df_temp = df_temp.dropna()\n",
    "df_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URL=\"mongodb+srv://viphilongnguyen:egVQ0C3HhJRuVYaZ@cluster0.khgwh.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = pymongo.MongoClient(MONGO_URL)\n",
    "db = client.get_database('ASM3')\n",
    "\n",
    "def upsert_db(collection_name = '', documents = []):\n",
    "  upsertReqs = []\n",
    "  for document in documents:\n",
    "    upsertReqs.append(\n",
    "      pymongo.UpdateOne(\n",
    "        {'_id': document['_id']},\n",
    "        {'$set': document},\n",
    "        upsert=True\n",
    "      )\n",
    "    )\n",
    "  \n",
    "  collection = db[collection_name]\n",
    "  collection.bulk_write(upsertReqs)\n",
    "  \n",
    "\n",
    "def delete_db(collectionName = '', documents = []):\n",
    "    delReqs = []\n",
    "    for document in documents:\n",
    "        delReqs.append(\n",
    "            pymongo.DeleteOne(\n",
    "                {'_id': document['_id']}\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    collection = db[collectionName]\n",
    "    collection.bulk_write(delReqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_dict = df_temp.to_dict(orient='records')\n",
    "upsert_db('combine_clean', df_temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
